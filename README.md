# Data Engineering with AWS
Data Pipe Lines with AWS

# Introduction & Goals
- The project is about building data pipeline for Credit Card Complaints data.  It takes the general [blueprint](https://github.com/andkret/Cookbook/blob/master/sections/01-Introduction.md#my-data-science-platform-blueprint) as a baseline for selecting data sources, processing and buffer framework, storage and visualization tools.


This Project has mainly classified into three phases,

  - Initial phase : Research on the industries about technical stack that are used in Data Engineering.

    Choosing your data source.

  - Second Phase : Designing and developing the pipeline with tools and data source.
  - Third Phase : Documentation for the project and grouping the code used in various phases of development

  #### With what data are you working 
  I am working with credit card complaints data and nuances of [dataset](#the-data-set) has been explained in my [blog](https://www.teamdatascience.com/post/data-sets)
  
  #### Tools that i used are 

  I choose managed services provided by Amazon, which are server less environments and offer greater capability at scale.
    - AWS(Lambda, kinesis, Kinesis Firehouse, Redshift, Dynamodb, S3 )
    - Docker
    - Power BI
    - Apache Airflow
    - IDE and coding
  
  #### What are you doing with these tools

  Data pipelines in this project uses, *Lambda* as a processing environment.  To handle streaming data *Kinesis* will come to rescue and they acts as a buffer too.  Eventually data is stored in warehouses, NoSql or file system storage solution.


  - Once you are finished add the conclusion here as well


# Contents

- [The Data Set](#the-data-set)
- [Used Tools](#used-tools)
- [Pipelines](#pipelines)
  - [Stream Processing](#stream-processing)
    - [Storing Data Stream](#storing-data-stream)
    - [Processing Data Stream](#processing-data-stream)
  - [Batch Processing](#batch-processing)
  - [Visualizations](#visualizations)
- [Demo](#demo)
- [Conclusion](#conclusion)
- [Follow Me On](#follow-me-on)
- [Appendix](#appendix)


# The Data Set
- [About my dataset](Contents/Dataset.MD)
- [Why did I choose it?](Contents/Dataset.MD)
- [What do you like about it?](Contents/Dataset.MD)
- [What is problematic?](Contents/Dataset.MD)
- [What do you want to do with it?](Contents/Dataset.MD)

# Used Tools
- [Tools I used](Contents/Tools.MD)
- [How do they work]((Contents/Tools.MD))
- [Why I choose them](Contents/Tools.MD)
- [Tools Setup](Contents/Tools.MD)

# Pipelines
- Explain the pipelines for processing that you are building
- Go through your development and add your source code

## Stream Processing
### Storing Data Stream
### Processing Data Stream
## Batch Processing
## Visualizations

# Demo
- You could add a demo video here
- Or link to your presentation video of the project

# Conclusion
Write a comprehensive conclusion.
- How did this project turn out
- What major things have you learned
- What were the biggest challenges

# Follow Me On
Add the link to your LinkedIn Profile

# Appendix

[Markdown Cheat Sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)
